# AuxiliaryTools
本脚本中包含一些NLP任务中基本的操作:分句(英文)、分词(中、英)、识别语种(所有).
## 一、Participle_word_tool
#### 1.[Participle_word_tool:](https://github.com/Shajiu/AuxiliaryTools/blob/master/Participle_word_tool/divide_paper.py) 英文文本分词工具
 
